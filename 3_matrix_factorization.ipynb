{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix Factorization\n",
    "\n",
    "### 1. What is matrix factorization?\n",
    "Mathematically, an N×M matrix can be decomposed into several smaller matrices through matrix factorization. When these smaller matrices are multiplied together, they reconstruct the original N×M matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Applications?\n",
    "- `Collaborative Filtering for Recommendations`: Used in recommendation systems to predict user preferences.\n",
    "- `Dimensionality Reduction`: Helps reduce the number of random variables under consideration.\n",
    "- `Image Compression and Denoising`: Enhances image processing by reducing noise and compressing image data.\n",
    "- `Text Mining and Topic Modeling`: Facilitates the extraction of meaningful patterns and topics from large text corpora."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Some of the Matrix Factorization Algorithms\n",
    "- LU Decomposition\n",
    "- Singular Value Decomposition\n",
    "- QR Decomposition\n",
    "- Cholesky Decomposition\n",
    "- Eigenvalue Decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. LU Decomposition\n",
    "LU decomposition stands for Lower triangular - Upper triangular Decomposition. In this process, an N×M matrix is decomposed into two matrices: one is a lower triangular matrix, and the other is an upper triangular matrix.\n",
    "\n",
    "A = L x U\n",
    "\n",
    "![image](./images/LU.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- LU Decomposition uses Gaussian Elimination to get to these matrices.\n",
    "- What is Gaussian Elimination/Row Reduction?\n",
    "  - It aims at converting a matrix into a Upper Triangular matrix by applying Linear row operations like\n",
    "  - `Row2 = Row2 – 3 x Row3`\n",
    "  - `Row1 = Row1 + Row x 2/5`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example\n",
    "Given matrix \\( A \\):\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "3 & 1 & 2 \\\\\n",
    "6 & 3 & 4 \\\\\n",
    "3 & 1 & 5\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "We want to decompose $A$ into a lower triangular matrix $L$ and an upper triangular matrix $U$ such that $A = LU$.\n",
    "\n",
    "### Steps\n",
    "\n",
    "### 1. Initialize $L$ and $U$\n",
    "\n",
    "- $U$ will be initialized as $A$.\n",
    "- $L$ will be an identity matrix of the same size as $A$.\n",
    "\n",
    "$$\n",
    "L = \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 1\n",
    "\\end{pmatrix}, \\quad\n",
    "U = \\begin{pmatrix}\n",
    "3 & 1 & 2 \\\\\n",
    "6 & 3 & 4 \\\\\n",
    "3 & 1 & 5\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 2. First Elimination Step (eliminate $U_{21}$ and $U_{31}$)\n",
    "\n",
    "- Multiply the first row by $2$ (the element $U_{21}$ divided by the pivot $U_{11}$ )and subtract it from the second row.\n",
    "- Multiply the first row by $1$ (the element $U_{31}$ divided by the pivot $U_{11}$ ) and subtract it from the third row.\n",
    "\n",
    "$$\n",
    "L = \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "2 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "U = \\begin{pmatrix}\n",
    "3 & 1 & 2 \\\\\n",
    "6 - 2 \\cdot 3 & 3 - 2 \\cdot 1 & 4 - 2 \\cdot 2 \\\\\n",
    "3 - 1 \\cdot 3 & 1 - 1 \\cdot 1 & 5 - 1 \\cdot 2\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Simplifying the calculations:\n",
    "\n",
    "$$\n",
    "U = \\begin{pmatrix}\n",
    "3 & 1 & 2 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### 3. Second Elimination Step (eliminate $U_{32}$)\n",
    "\n",
    "- The second row remains unchanged as there is no need for further elimination.\n",
    "- The third row is already in the correct form, with zeros below the diagonal.\n",
    "\n",
    "So, the $L$ and $U$ matrices are:\n",
    "\n",
    "$$\n",
    "L = \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "2 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}, \\quad\n",
    "U = \\begin{pmatrix}\n",
    "3 & 1 & 2 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 3\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Thus, the LU decomposition of matrix $A$ is:\n",
    "\n",
    "$$\n",
    "A = LU\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "$$\n",
    "L = \\begin{pmatrix}\n",
    "1 & 0 & 0 \\\\\n",
    "2 & 1 & 0 \\\\\n",
    "1 & 0 & 1\n",
    "\\end{pmatrix}, \\quad\n",
    "U = \\begin{pmatrix}\n",
    "3 & 1 & 2 \\\\\n",
    "0 & 1 & 0 \\\\\n",
    "0 & 0 & 3\n",
    "\\end{pmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Eigenvalue/Spectral Decomposition\n",
    "- `Eigenvectors` = For a square matrix A, an eigenvector is a non-zero vector that, when multiplied by the matrix A, only changes in scale (magnitude) but retains its direction.\n",
    "\n",
    "- `Eigenvalues` = The corresponding scale factor associated with eigenvector is called the eigenvalue.\n",
    "- You must have read about Eigenvalues and Eigenvectors while reading about PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relation between eigenvector,eigenvalues and matrix A is represented by below mathematical equation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A * v = λ*v or\n",
    "\n",
    "A*v —λ*v = 0 or\n",
    "\n",
    "(A-λI)* v = 0\n",
    "\n",
    "    Where:\n",
    "    A: Square matrix\n",
    "    v: Eigenvector\n",
    "    λ (lambda): Eigenvalue\n",
    "\n",
    "    I: identity matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eigenvalues and Eigenvectors\n",
    "\n",
    "Given matrix $A$:\n",
    "\n",
    "$$\n",
    "A = \\begin{pmatrix}\n",
    "4 & 1 & 2 \\\\\n",
    "1 & 5 & 6 \\\\\n",
    "2 & 6 & 7\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "we need to find the eigenvalues and eigenvectors of $A$.\n",
    "\n",
    "## Eigenvalues\n",
    "\n",
    "To find the eigenvalues, we solve the characteristic equation:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) = 0\n",
    "$$\n",
    "\n",
    "where $I$ is the identity matrix and $\\lambda$ is an eigenvalue of $A$.\n",
    "\n",
    "First, calculate $A - \\lambda I$:\n",
    "\n",
    "$$\n",
    "A - \\lambda I = \\begin{pmatrix}\n",
    "4 - \\lambda & 1 & 2 \\\\\n",
    "1 & 5 - \\lambda & 6 \\\\\n",
    "2 & 6 & 7 - \\lambda\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Next, find the determinant of this matrix:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) = \\begin{vmatrix}\n",
    "4 - \\lambda & 1 & 2 \\\\\n",
    "1 & 5 - \\lambda & 6 \\\\\n",
    "2 & 6 & 7 - \\lambda\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "Using the rule for the determinant of a $3 \\times 3$ matrix, we have:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) = (4 - \\lambda) \\begin{vmatrix}\n",
    "5 - \\lambda & 6 \\\\\n",
    "6 & 7 - \\lambda\n",
    "\\end{vmatrix}\n",
    "- 1 \\begin{vmatrix}\n",
    "1 & 6 \\\\\n",
    "2 & 7 - \\lambda\n",
    "\\end{vmatrix}\n",
    "+ 2 \\begin{vmatrix}\n",
    "1 & 5 - \\lambda \\\\\n",
    "2 & 6\n",
    "\\end{vmatrix}\n",
    "$$\n",
    "\n",
    "Now, compute each $2 \\times 2$ determinant:\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "5 - \\lambda & 6 \\\\\n",
    "6 & 7 - \\lambda\n",
    "\\end{vmatrix}\n",
    "= (5 - \\lambda)(7 - \\lambda) - 6 \\cdot 6 = \\lambda^2 - 12\\lambda + 1\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 & 6 \\\\\n",
    "2 & 7 - \\lambda\n",
    "\\end{vmatrix}\n",
    "= 1 \\cdot (7 - \\lambda) - 6 \\cdot 2 = 7 - \\lambda - 12 = -\\lambda - 5\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{vmatrix}\n",
    "1 & 5 - \\lambda \\\\\n",
    "2 & 6\n",
    "\\end{vmatrix}\n",
    "= 1 \\cdot 6 - 2 \\cdot (5 - \\lambda) = 6 - 10 + 2\\lambda = 2\\lambda - 4\n",
    "$$\n",
    "\n",
    "Substitute these back into the determinant equation:\n",
    "\n",
    "$$\n",
    "\\det(A - \\lambda I) = (4 - \\lambda)(\\lambda^2 - 12\\lambda + 1) - (-\\lambda - 5) + 2(2\\lambda - 4)\n",
    "$$\n",
    "\n",
    "Simplify and solve for $\\lambda$:\n",
    "\n",
    "$$\n",
    "(4 - \\lambda)(\\lambda^2 - 12\\lambda + 1) + \\lambda + 5 + 4\\lambda - 8 = 0\n",
    "$$\n",
    "\n",
    "$$\n",
    "(4 - \\lambda)(\\lambda^2 - 12\\lambda + 1) + 5\\lambda - 3 = 0\n",
    "$$\n",
    "\n",
    "Expanding and simplifying further will give the polynomial whose roots are the eigenvalues.\n",
    "\n",
    "The characteristic polynomial is:\n",
    "\n",
    "$$\n",
    "\\lambda^3 - 16\\lambda^2 - 7\\lambda + 41 = 0\n",
    "$$\n",
    "\n",
    "Solving this polynomial, the eigenvalues are approximately:\n",
    "\n",
    "$$\n",
    "\\lambda_1 \\approx 12.2652, \\quad \\lambda_2 \\approx -1.7348, \\quad \\lambda_3 \\approx 5.4696\n",
    "$$\n",
    "\n",
    "## Eigenvectors\n",
    "\n",
    "### Eigenvector for $\\lambda_1 \\approx 12.2652$\n",
    "\n",
    "For $\\lambda_1 \\approx 12.2652$, solve:\n",
    "\n",
    "$$\n",
    "A - \\lambda_1 I = \\begin{pmatrix}\n",
    "4 - 12.2652 & 1 & 2 \\\\\n",
    "1 & 5 - 12.2652 & 6 \\\\\n",
    "2 & 6 & 7 - 12.2652\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "-8.2652 & 1 & 2 \\\\\n",
    "1 & -7.2652 & 6 \\\\\n",
    "2 & 6 & -5.2652\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Solving $(A - \\lambda_1 I) \\mathbf{v} = 0$:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "-8.2652 & 1 & 2 \\\\\n",
    "1 & -7.2652 & 6 \\\\\n",
    "2 & 6 & -5.2652\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "v_1 \\\\\n",
    "v_2 \\\\\n",
    "v_3\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The eigenvector $\\mathbf{v}_1$ corresponding to $\\lambda_1$ is approximately:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_1 \\approx \\begin{pmatrix}\n",
    "0.3482 \\\\\n",
    "0.6152 \\\\\n",
    "0.7071\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Eigenvector for $\\lambda_2 \\approx -1.7348$\n",
    "\n",
    "For $\\lambda_2 \\approx -1.7348$, solve:\n",
    "\n",
    "$$\n",
    "A - \\lambda_2 I = \\begin{pmatrix}\n",
    "4 - (-1.7348) & 1 & 2 \\\\\n",
    "1 & 5 - (-1.7348) & 6 \\\\\n",
    "2 & 6 & 7 - (-1.7348)\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "5.7348 & 1 & 2 \\\\\n",
    "1 & 6.7348 & 6 \\\\\n",
    "2 & 6 & 8.7348\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Solving $(A - \\lambda_2 I) \\mathbf{v} = 0$:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "5.7348 & 1 & 2 \\\\\n",
    "1 & 6.7348 & 6 \\\\\n",
    "2 & 6 & 8.7348\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "v_1 \\\\\n",
    "v_2 \\\\\n",
    "v_3\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The eigenvector $\\mathbf{v}_2$ corresponding to $\\lambda_2$ is approximately:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_2 \\approx \\begin{pmatrix}\n",
    "0.7851 \\\\\n",
    "-0.2647 \\\\\n",
    "-0.5609\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "### Eigenvector for $\\lambda_3 \\approx 5.4696$\n",
    "\n",
    "For $\\lambda_3 \\approx 5.4696$, solve:\n",
    "\n",
    "$$\n",
    "A - \\lambda_3 I = \\begin{pmatrix}\n",
    "4 - 5.4696 & 1 & 2 \\\\\n",
    "1 & 5 - 5.4696 & 6 \\\\\n",
    "2 & 6 & 7 - 5.4696\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "-1.4696 & 1 & 2 \\\\\n",
    "1 & -0.4696 & 6 \\\\\n",
    "2 & 6 & 1.5304\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "Solving $(A - \\lambda_3 I) \\mathbf{v} = 0$:\n",
    "\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "-1.4696 & 1 & 2 \\\\\n",
    "1 & -0.4696 & 6 \\\\\n",
    "2 & 6 & 1.5304\n",
    "\\end{pmatrix}\n",
    "\\begin{pmatrix}\n",
    "v_1 \\\\\n",
    "v_2 \\\\\n",
    "v_3\n",
    "\\end{pmatrix}\n",
    "= \\begin{pmatrix}\n",
    "0 \\\\\n",
    "0 \\\\\n",
    "0\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "The eigenvector $\\mathbf{v}_3$ corresponding to $\\lambda_3$ is approximately:\n",
    "\n",
    "$$\n",
    "\\mathbf{v}_3 \\approx \\begin{pmatrix}\n",
    "-0.5094 \\\\\n",
    "0.7423 \\\\\n",
    "-0.4357\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "## Summary\n",
    "\n",
    "The eigenvalues and corresponding eigenvectors of matrix $A$ are:\n",
    "\n",
    "$$\n",
    "\\lambda_1 \\approx 12.2652, \\quad \\mathbf{v}_1 \\approx \\begin{pmatrix}\n",
    "0.3482 \\\\\n",
    "0.6152 \\\\\n",
    "0.7071\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda_2 \\approx -1.7348, \\quad \\mathbf{v}_2 \\approx \\begin{pmatrix}\n",
    "0.7851 \\\\\n",
    "-0.2647 \\\\\n",
    "-0.5609\n",
    "\\end{pmatrix}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\lambda_3 \\approx 5.4696, \\quad \\mathbf{v}_3 \\approx \\begin{pmatrix}\n",
    "-0.5094 \\\\\n",
    "0.7423 \\\\\n",
    "-0.4357\n",
    "\\end{pmatrix}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C. Singular Vector Decomposition\n",
    "As LU Decomposition decomposes the actual matrix into 2 subsequent matrices, SVD decomposes it into 3 matrices extending the idea of Eigenvalue decomposition. A couple of concepts we must know to understand SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Singular values = square_root(eigen values)\n",
    "- Singular vector = Normalized eigen vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SVD decomposition is represented as:\n",
    "\n",
    "    A = U x Σ x Vᵀ\n",
    "\n",
    "    Where:\n",
    "    A: The original matrix  \n",
    "    U: U is the left singular matrix  \n",
    "\n",
    "    Σ: The singular values matrix (diagonal matrix)  \n",
    "    V: Right singular vectors matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Steps:\n",
    "- Calculate Aᵀ x A. Lets call this A⁻\n",
    "- Calculate eigenvalues and eigenvectors for A⁻ (as shown above in eigen value decomposition)\n",
    "- Calculate singular values for A⁻ using root of eigenvalues. These values will be used to form Σ (diagonal matrix)\n",
    "- Calculate singular vectors for A⁻ by normalizing calculated eigenvectors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,\n",
    "\n",
    "    V = matrix of singular vectors of A⁻\n",
    "\n",
    "    Σ = diagonal matrix with distinct singular values\n",
    "\n",
    "    To calculate U, we will use the relation A = U x Σ x Vᵀ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As A, Σ, Vᵀ are known, U can be calculated by U = A x V x Σᵀ.\n",
    "\n",
    "This a really [nice example](https://medium.com/intuition/singular-value-decomposition-svd-working-example-c2b6135673b5) for referencing how SVD is calculated with an example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### D. QR Decomposition\n",
    "Similar to LU Decomposition, QR decomposition decomposes a matrix into 2 matrices, Q & R where\n",
    "\n",
    "Q = Orthonormal matrix\n",
    "\n",
    "R = Upper Triangular matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check [this](https://www.math.ucla.edu/~yanovsky/Teaching/Math151B/handouts/GramSchmidt.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### E. Cholesky Decomposition\n",
    "It decomposes the actual matrix such that\n",
    "\n",
    "    A = L x Lᵀ\n",
    "\n",
    "where L is a Lower triangular matrix. To find such a lower triangular matrix, the below functions are used\n",
    "\n",
    "    L₁₁ = √A₁₁\n",
    "\n",
    "    Lᵢ₁ = Aᵢ₁/L₁₁ (1st column of L)\n",
    "\n",
    "    Lᵢᵢ= √(Aᵢᵢ — Σₚ Lᵢₚ²), p= 1 →i-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so if L₃₃ = √(A₃₃ — (L²₃₁+L²₃₂))\n",
    "\n",
    "    Lᵢⱼ =1/Lⱼⱼ (Aᵢⱼ — Σₚ(Lᵢₚ * Lⱼₚ), i>j, p →1,i-1\n",
    "\n",
    "for L₄₃ = 1/L₃₃ (A₄₃ — (L₄₁*L₃₁+L₄₂*L₃₂))\n",
    "\n",
    "Where\n",
    "\n",
    "L = Lower triangular matrix\n",
    "\n",
    "A = Actual matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Which method when to use?\n",
    "- LU Decomposition: Square matrices.\n",
    "- Eigenvalue Decomposition: Square matrices that are diagonalizable.\n",
    "- Cholesky Decomposition: Symmetric and positive definite matrices.\n",
    "- QR Decomposition: Any type of matrix\n",
    "- Singular Value Decomposition (SVD): Any type of matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
